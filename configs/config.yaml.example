# QNG Agent 配置示例
# 复制此文件为 config.yaml 并根据需要修改

llm:
  # 选择LLM提供商: openai, anthropic, ollama, gemini
  provider: "openai"
  
  configs:
    # === OpenAI 配置 ===
    openai_api_key: "YOUR_OPENAI_API_KEY"
    openai_base_url: "https://api.openai.com/v1"
    
    # === Anthropic 配置 ===
    anthropic_api_key: "YOUR_ANTHROPIC_API_KEY"
    
    # === Ollama 本地配置 ===
    # 需要先安装并启动 Ollama: https://ollama.ai
    ollama_base_url: "http://localhost:11434"
    
    # === Google Gemini 配置 ===
    # 获取API Key: https://makersuite.google.com/app/apikey
    gemini_api_key: "YOUR_GEMINI_API_KEY"
    gemini_base_url: "https://generativelanguage.googleapis.com/v1beta"
    
    # === 模型配置 ===
    # 根据provider选择对应模型:
    # OpenAI: gpt-4, gpt-3.5-turbo, gpt-4-turbo
    # Anthropic: claude-3-sonnet-20240229, claude-3-haiku-20240307
    # Ollama: llama3, llama2, codellama, mistral, qwen
    # Gemini: gemini-pro, gemini-pro-vision
    model: "gpt-4"

# MCP 服务配置
mcp:
  timeout: 30

# QNG 链配置
qng:
  chain_rpc: "http://localhost:8545"
  graph_nodes: 5
  poll_interval: 1000

# MetaMask 配置
metamask:
  network: "ethereum"

# UI 配置
ui:
  port: 9090
  static: "./web/dist"

# === 使用说明 ===
# 
# 1. OpenAI 配置:
#    - 获取API Key: https://platform.openai.com/api-keys
#    - 支持自定义base_url（如使用代理）
#
# 2. Anthropic 配置:
#    - 获取API Key: https://console.anthropic.com/
#    - 支持Claude 3系列模型
#
# 3. Ollama 本地配置:
#    - 安装Ollama: https://ollama.ai
#    - 启动服务: ollama serve
#    - 拉取模型: ollama pull llama3
#
# 4. Google Gemini 配置:
#    - 获取API Key: https://makersuite.google.com/app/apikey
#    - 支持Gemini Pro和Vision模型
#
# 5. 切换提供商:
#    - 修改 llm.provider 值
#    - 确保对应的API Key已配置
#    - 选择合适的模型 